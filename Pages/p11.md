# 🌟 **Tutorial: Multiple Testing Corrections**

### 📌 **1. Why Multiple Testing Corrections?**

✅ **Problem:**
When conducting **multiple hypothesis tests**, the chance of getting **false positives (Type I errors)** increases.

✔️ **Example:**
If you test 20 hypotheses at α=0.05, there is a high chance (≈64%) of at least one false positive by random chance.

---

### 📌 **2. Bonferroni Correction**

✅ **Definition:**
A **conservative method** that controls **Family-Wise Error Rate (FWER)** by adjusting α downwards.

✔️ **Formula:**
$\alpha_{corrected} = \frac{\alpha}{n}$

Where **n** = number of tests.

---

### 🔧 **Example:**

If testing **5 hypotheses** with α=0.05:

```python
alpha = 0.05
n_tests = 5

alpha_corrected = alpha / n_tests
print("Bonferroni corrected alpha:", alpha_corrected)
```

✅ **Interpretation:**
Each test must have **p-value < 0.01** to be considered significant.

---

### 📌 **Key Points about Bonferroni Correction:**

* Controls **FWER strongly**
* **Very conservative** → High chance of Type II errors (false negatives)
* Best when **few tests** or **high penalty for false positives**

---

## ✨ **3. False Discovery Rate (FDR) / Benjamini-Hochberg Procedure**

✅ **Definition:**
Controls the **expected proportion of false positives among the rejected hypotheses** (less conservative than Bonferroni).

✔️ **Procedure (Benjamini-Hochberg):**

1. Rank p-values from smallest to largest.
2. Calculate:

$$
p_{BH} = \frac{i}{n} \times Q
$$

where **i** = rank, **n** = total tests, **Q** = desired FDR level (e.g. 0.05).

3. Find the largest p-value where **p ≤ p\_BH**. All p-values less than or equal to this are significant.

---

### 🔧 **Python Example:**

Using `statsmodels` to perform Benjamini-Hochberg correction:

```python
from statsmodels.stats.multitest import multipletests

# Example p-values
p_values = [0.01, 0.04, 0.03, 0.002, 0.05, 0.20, 0.07]

# Benjamini-Hochberg correction
rejected, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')

print("Reject null hypothesis:", rejected)
print("Corrected p-values:", pvals_corrected)
```

✅ **Interpretation:**

* **rejected:** Boolean array indicating which hypotheses remain significant after FDR correction.
* **pvals\_corrected:** Adjusted p-values.

---

### 📌 **Key Points about FDR / Benjamini-Hochberg:**

* Controls **proportion of false discoveries**
* **Less conservative** → more power than Bonferroni
* Best when testing **many hypotheses (e.g. genomics, multiple metrics)**

---

## ✅ **Summary Table**

| **Method**                   | **Controls**                  | **Use Case**                                   |
| ---------------------------- | ----------------------------- | ---------------------------------------------- |
| **Bonferroni Correction**    | Family-Wise Error Rate (FWER) | Few tests, strict control of Type I error      |
| **Benjamini-Hochberg (FDR)** | False Discovery Rate          | Many tests, tolerance for some false positives |

---

### 💡 **When to Use?**

* Use **Bonferroni** when **false positives are very costly** (e.g. medical trials).
* Use **FDR / Benjamini-Hochberg** when **exploring many hypotheses** (e.g. gene expression analysis) and some false positives are acceptable.

---

