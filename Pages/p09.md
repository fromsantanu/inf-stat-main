# üåü **Tutorial: Bayesian Inference (Basics)**

### üìå **1. What is Bayesian Inference?**

‚úÖ **Definition:**
A statistical approach that **updates the probability of a hypothesis as more evidence or data becomes available**.

‚úîÔ∏è **Key idea:**
Combines **prior belief** with **new data** to form an **updated (posterior) belief**.

---

## ‚ú® **2. Bayes‚Äô Theorem**

‚úÖ **Formula:**

$$
P(H|D) = \frac{P(D|H) \times P(H)}{P(D)}
$$

Where:

* **P(H|D):** Posterior probability (updated belief)
* **P(D|H):** Likelihood (data probability given hypothesis)
* **P(H):** Prior probability (initial belief)
* **P(D):** Evidence (overall probability of data)

---

### üîß **Example (Medical Test Problem):**

* Disease prevalence (P(Disease)) = 1% = 0.01
* Test sensitivity (P(Pos|Disease)) = 99% = 0.99
* Test false positive rate (P(Pos|No Disease)) = 5% = 0.05

‚úÖ **What is the probability that a person has the disease if tested positive?**

```python
# Given values
P_Disease = 0.01
P_Pos_given_Disease = 0.99
P_Pos_given_NoDisease = 0.05
P_NoDisease = 1 - P_Disease

# Calculate P(Pos)
P_Pos = (P_Pos_given_Disease * P_Disease) + (P_Pos_given_NoDisease * P_NoDisease)

# Calculate P(Disease|Pos)
P_Disease_given_Pos = (P_Pos_given_Disease * P_Disease) / P_Pos

print("Probability of Disease given Positive Test:", P_Disease_given_Pos)
```

‚úÖ **Interpretation:**
Even with a positive result, the **probability is \~17%**, showing the importance of considering prevalence (prior).

---

## ‚ú® **3. Posterior Distributions**

‚úÖ **Definition:**
The updated distribution representing **our belief about a parameter after seeing data**.

‚úîÔ∏è **Formula (Conceptual):**

$$
Posterior \propto Likelihood \times Prior
$$

üîß **Example (Beta-Binomial Conjugate Prior):**

* Prior belief: Beta(2,2) ‚Äì representing a fair coin with uncertainty
* Data: 8 heads in 10 tosses

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import beta

# Prior parameters
a_prior = 2
b_prior = 2

# Data
heads = 8
tails = 2

# Posterior parameters
a_post = a_prior + heads
b_post = b_prior + tails

# Plot
x = np.linspace(0, 1, 100)
prior = beta.pdf(x, a_prior, b_prior)
posterior = beta.pdf(x, a_post, b_post)

plt.plot(x, prior, label='Prior Beta(2,2)')
plt.plot(x, posterior, label='Posterior Beta(10,4)')
plt.xlabel('Probability of Heads')
plt.ylabel('Density')
plt.legend()
plt.show()
```

‚úÖ **Interpretation:**
The **posterior distribution** is shifted towards higher probability of heads after observing data.

---

## ‚ú® **4. Credible Intervals**

‚úÖ **Definition:**
The **Bayesian equivalent of confidence intervals**, representing the range within which the parameter lies with a certain probability (e.g. 95%).

‚úîÔ∏è **Example (using Beta posterior above):**

```python
cred_interval = beta.interval(0.95, a_post, b_post)
print("95% Credible Interval:", cred_interval)
```

‚úÖ **Interpretation:**
We are **95% confident** that the true probability of heads lies within this interval **given the data and prior belief**.

---

## ‚úÖ **Summary Table**

| **Concept**                | **Key Points**                                    |
| -------------------------- | ------------------------------------------------- |
| **Bayes‚Äô Theorem**         | Updates probability of hypothesis with new data   |
| **Posterior Distribution** | Updated belief combining prior and data           |
| **Credible Interval**      | Bayesian range for parameter with set probability |

---

### üí° **Key Differences from Frequentist Approach:**

| **Bayesian**                         | **Frequentist**                                      |
| ------------------------------------ | ---------------------------------------------------- |
| Uses **prior beliefs**               | No prior beliefs                                     |
| Gives **probability of parameters**  | Gives probability of observing data under hypothesis |
| Result is **posterior distribution** | Result is point estimate and confidence interval     |

---


